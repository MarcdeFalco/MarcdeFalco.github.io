<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="generator" content="pandoc">
    <meta name="description" content="">
    <meta name="author" content="Marc de Falco">

    <title>Introduction à l’analyse des algorithmes</title>

    <link rel="stylesheet" type="text/css" href="assets/semantic.min.css">
    <link href='//fonts.googleapis.com/css?family=Lato:300,400' rel='stylesheet' type='text/css'>

    <script
      src="https://code.jquery.com/jquery-3.1.1.min.js"
      integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="
      crossorigin="anonymous"></script>
    <script src="assets/semantic.min.js"></script>

    <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script>
$(document).ready(function() {
    
    $("#toc").sidebar("setting", "dimPage", false);
    if (matchMedia) {
        var mq = window.matchMedia("(max-width: 700px)");
        mq.addListener(big_or_small);
        big_or_small(mq);
    }

    function big_or_small(mq) {
        // The sidebar *pushes* the pusher, the main content, so we
        // add a class that reduces the pusher's width so the edge
        // content isn't cut off.
        if (mq.matches) {
	    $("#toc").sidebar("hide");
            $("#main").removeClass("shrink")
        } else {
            $("#toc").sidebar("show");
            $("#main").addClass("shrink");
        }
    }

    $("#sidebar-menu-button").click(function() {
        $("#toc").sidebar("show");
    }).end();

   //$('.sidebar').children().addClass('vertical inverted menu');
   //$('.sidebar').find('ul').addClass('ui');
   //$('.sidebar').find('li').addClass('ui');
   var links = $('.ui.sidebar').find('a').addClass('item');
    $('.ui.sidebar').append(links);
    $('.ui.sidebar').find('ul').detach();
    $('.ui.sidebar').find('li').detach();
})
</script>

  <style type="text/css">

  .ui.sidebar {
    font-size: 18px;
  }

  body {
    background-color: #FFFFFF;
    font-size: 20px;
  }
  .ui.segment {
    font-size: 20px;
  }
  .wireframe {
    //margin-top: 2em;
  }
  .ui.footer.segment {
    //margin: 5em 0em 0em;
    //padding: 5em 0em;
  }
  #top-menu {
    display: none;
}

    .message {
        color: #000 !important;
    }

.shrink {
    width: 60%;
}

@media only screen and (max-width: 700px) {
    #top-menu {
        display: block !important;
    }
}
  </style>

  </head>
  <body class="pushable class="pushable"">


<div class="ui vertical inverted visible fixed sidebar menu" id="toc">
<a href="index.html" class="item">
    Informatique en CPGE
</a>
<ul>
<li><a href="#sec:terminaison"><span class="toc-section-number">1</span> Terminaison</a>
<ul>
<li><a href="#sec:variant-de-boucle"><span class="toc-section-number">1.1</span> Variant de boucle</a></li>
<li><a href="#sec:exemple-de-la-recherche-dichotomique"><span class="toc-section-number">1.2</span> Exemple de la recherche dichotomique</a></li>
</ul></li>
<li><a href="#sec:correction"><span class="toc-section-number">2</span> Correction</a>
<ul>
<li><a href="#sec:invariant-de-boucle"><span class="toc-section-number">2.1</span> Invariant de boucle</a></li>
<li><a href="#sec:exemple-du-tri-par-sélection"><span class="toc-section-number">2.2</span> Exemple du tri par sélection</a></li>
</ul></li>
<li><a href="#sec:complexité"><span class="toc-section-number">3</span> Complexité</a>
<ul>
<li><a href="#sec:complexité-dans-le-pire-des-cas"><span class="toc-section-number">3.1</span> Complexité dans le pire des cas</a></li>
<li><a href="#sec:comparer-des-complexités"><span class="toc-section-number">3.2</span> Comparer des complexités</a>
<ul>
<li><a href="#sec:la-notation-grand-o"><span class="toc-section-number">3.2.1</span> La notation grand O</a></li>
<li><a href="#sec:échelle-de-comparaison"><span class="toc-section-number">3.2.2</span> Échelle de comparaison</a></li>
<li><a href="#sec:ordre-de-grandeur-et-relation-theta"><span class="toc-section-number">3.2.3</span> Ordre de grandeur et relation <span class="math inline">\(\Theta\)</span></a></li>
<li><a href="#sec:opérations-sur-les-grands-o"><span class="toc-section-number">3.2.4</span> Opérations sur les grands O</a></li>
</ul></li>
<li><a href="#sec:complexités-en-temps-classiques"><span class="toc-section-number">3.3</span> Complexités en temps classiques</a>
<ul>
<li><a href="#sec:complexité-constante"><span class="toc-section-number">3.3.1</span> Complexité constante</a></li>
<li><a href="#sec:complexité-linéaire"><span class="toc-section-number">3.3.2</span> Complexité linéaire</a></li>
<li><a href="#sec:complexité-quadratique-polynomiale"><span class="toc-section-number">3.3.3</span> Complexité quadratique, polynomiale</a></li>
<li><a href="#sec:complexité-logarithmique"><span class="toc-section-number">3.3.4</span> Complexité logarithmique</a></li>
<li><a href="#sec:complexité-quasi-linéaire"><span class="toc-section-number">3.3.5</span> Complexité quasi-linéaire</a></li>
<li><a href="#sec:complexité-exponentielle"><span class="toc-section-number">3.3.6</span> Complexité exponentielle</a></li>
<li><a href="#sec:estimation-de-limpact-des-complexités-sur-le-temps"><span class="toc-section-number">3.3.7</span> Estimation de l’impact des complexités sur le temps</a></li>
</ul></li>
<li><a href="#sec:calculer-des-complexités"><span class="toc-section-number">3.4</span> Calculer des complexités</a></li>
<li><a href="#sec:complexité-à-plusieurs-paramètres"><span class="toc-section-number">3.5</span> Complexité à plusieurs paramètres</a>
<ul>
<li><a href="#sec:données-multidimensionnelles"><span class="toc-section-number">3.5.1</span> Données multidimensionnelles</a></li>
<li><a href="#sec:compromis-entre-paramètres"><span class="toc-section-number">3.5.2</span> Compromis entre paramètres</a></li>
</ul></li>
<li><a href="#sec:complexité-en-moyenne"><span class="toc-section-number">3.6</span> Complexité en moyenne</a>
<ul>
<li><a href="#sec:exemple-de-calcul-de-complexité-temporelle-en-moyenne"><span class="toc-section-number">3.6.1</span> Exemple de calcul de complexité temporelle en moyenne</a></li>
</ul></li>
<li><a href="#sec:complexité-amortie"><span class="toc-section-number">3.7</span> Complexité amortie</a></li>
<li><a href="#sec:pertinence-de-la-complexité-spatiale"><span class="toc-section-number">3.8</span> Pertinence de la complexité spatiale</a></li>
</ul></li>
</ul>
</div>

<div class="pusher" id="main-content">
    <div class="ui inverted top menu" id="top-menu">
        <div class="ui container">
	  <a class="launch icon item" id="sidebar-menu-button">
	    <i class="content icon"></i>
	  </a>
	  <div class="item">
          Introduction à l’analyse des algorithmes
	  </div>
        </div>
      </div>
      <div class="ui padded basic segment" id="main">
\(
\def\N{{\mathbb{N}}}
\def\R{{\mathbb{R}}}
\def\D{{\mathbb{D}}}
\def\C{{\mathbb{C}}}
\def\Z{{\mathbb{Z}}}
\def\Q{{\mathbb{Q}}}
\def\K{{\mathbb{K}}}
\def\KX{{\mathbb{K}}[X]}
\def\U{{\mathbb{U}}}
\def\B{{\mathcal{B}}}

\newcommand\ensfonctions[2]{\mathcal{F}(#1,#2)}
\newcommand\ensfonctionszero[3]{\mathcal{F}_{#3,0}(#1,#2)}
\newcommand\continues[2]{\mathcal{C}(#1,#2)}
\newcommand\lineaires[2]{\mathcal{L}(#1,#2)}
\newcommand\nlineaires[3]{\mathcal{L}_{#1}(#2,#3)}
\newcommand\ensendo[1]{\mathcal{L}(#1)}
\newcommand\derivables[2]{\mathcal{D}(#1,#2)}
\newcommand\segment[2]{[#1,#2]}
\newcommand\intouvert[2]{]#1,#2[}
\newcommand\intouvertgauche[2]{]#1,#2]}
\newcommand\intouvertdroite[2]{[#1,#2[}
\newcommand\classeck[3]{\mathcal{C}^{#1}(#2,#3)}
\newcommand\range[2]{[| #1,#2 |]}
\newcommand\voisinages[2]{\mathcal{V}_{#1}(#2)}
\newcommand\matrices[3]{\mathcal{M}_{#1,#2}(#3)}
\newcommand\matricescarres[2]{\mathcal{M}_{#1}(#2)}
\newcommand\gln[2]{\mbox{GL}_{#1}(#2)}
\newcommand\Vect[1]{\mbox{Vect}(#1)}
\newcommand\Support[1]{\mbox{Supp}(#1)}
\newcommand\rang[1]{\mbox{rg}(#1)}
\newcommand\trace[1]{\mbox{tr}(#1)}
\newcommand\gl[1]{\mbox{GL}(#1)}
\newcommand\dom[0]{\mbox{dom}}
\newcommand\codim[0]{\mbox{codim}}
\newcommand\tr{\mbox{tr}}
\newcommand\uniondisjointe{\sqcup}
\def\Rbar{\overline\R}
\def\lt{<}
\def\rR{\mathcal{R}}
\newcommand\parties[1]{\mathcal{P}(#1)}
\newcommand\entiere[1]{\left\lfloor #1 \right\rfloor}
\newcommand\congru[3]{#1 = #2\ [#3]}
\newcommand\enscomp[2]{\left\{\left.\ #1\ \right|\ #2\ \right\}}
\newcommand\classe[1]{\overline{#1}}
\newcommand\classemod[2]{\overline{#1}^{[#2]}}
\newcommand\quotient[2]{#1 / #2}
\newcommand\ZnZ[1]{\quotient{\Z}{#1 \Z}}
\newcommand\card[1]{\text{Card}\ #1}
\newcommand\Det{\mbox{Det}}
\newcommand\indic{\mathbbm{1}}
\newcommand\groupeengendre[1]{\langle #1 \rangle}
\renewcommand\Im{\mathfrak{I}}
\newcommand\id{\mbox{id}}
\newcommand\Bary[1]{\mbox{Bary}\{#1\}}
\newcommand\Ker{\mbox{Ker}~}
\newcommand\Ima{\mbox{Im}~}
\newcommand\Perm[1]{\mathfrak{S}_#1}
\newcommand\comb[2]{\binom{#1}{#2}}
\newcommand\tend[2]{\xrightarrow[#1 \rightarrow #2]{}}
\newcommand\limite[2]{\lim_{#1 \rightarrow #2}}
\newcommand\sh{\mbox{sh}}
\newcommand\ch{\mbox{ch}}
\renewcommand\tanh{\mbox{th}}
\newcommand\Arcsin{\mbox{Arcsin}~}
\newcommand\Arccos{\mbox{Arccos}~}
\newcommand\Arctan{\mbox{Arctan}~}
\newcommand\Argsh{\mbox{Argsh}}
\newcommand\Argch{\mbox{Argch}}
\newcommand\Argth{\mbox{Argth}}
\newcommand\argu{\mbox{arg}}
\newcommand\dron[2]{\frac{\partial #1}{\partial #2}}
\newcommand\conj[1]{\overline{#1}}
\newcommand\ei[1]{e^{i #1}}
\newcommand\eii[2]{e^{#1 i #2}}
\newcommand\crochet[1]{\left[ #1 \right]}

\newcommand\application[5]{\begin{array}{rcccc}
#1 & : & #2 & \mapsto & #3 \\ 
& & #4 & \mapsto & #5
\end{array}}

\newcommand{\diff}{\mathop{}\mathopen{}\mathrm{d}}
\newcommand{\cc}{{\cal C}}

\)

<div class="masthead">
<div class="segment">
<center>
    <h1>Introduction à l’analyse des algorithmes</h1>
</center>
</div>
</div>
<div class="ui container text">
<p><img class="ui image fluid" src="assets/pics/chap_algo_exacte.png"/></p>
<p><em>Source de l’image d’en-tête <a href="https://xkcd.com/1667/">XKCD #1667</a></em></p>
<p><div class="ui message orange"><div class="header">Remarque</div>Ce chapitre présente les trois grands principes qui nous serviront de guide pour analyser les algorithmes et les programmes :</p>
<ul>
<li>La <strong>terminaison</strong> : l’algorithme termine-t-il au bout d’un nombre fini d’étapes quelle que soit l’entrée ?</li>
<li>La <strong>correction</strong> : le résultat rendu est-il celui qui était attendu ?</li>
<li>La <strong>complexité</strong> : combien de temps prend le programme selon la taille de l’entrée ? Combien d’espace mémoire occupe-t-il ?</li>
</ul>
<p>Savoir répondre à ces questions, c’est pouvoir prédire, avant d’avoir écrit la moindre ligne de code, ce qui va se passer.</div></p>
<h1 data-number="1" id="sec:terminaison"><span class="header-section-number">1</span> Terminaison</h1>
<p><div class="ui message"><div class="header">Définition</div> On dit qu’un algorithme <strong>termine</strong> quand il n’exécute qu’un nombre fini d’étapes sur toute entrée. </div></p>
<p><div class="ui message orange"><div class="header">Remarque</div>Cela n’empêche pas que ce nombre d’étapes puisse être arbitrairement grand en fonction des entrées.</div></p>
<p>Un algorithme qui n’utilise ni boucles inconditionnelles ni récursivité termine toujours. Ainsi, la question de la terminaison n’est à considérer que dans ces deux cas.</p>
<p>Considérons par exemple l’algorithme suivant qui, étant donné un entier naturel <span class="math inline">\(n\)</span> strictement positif, inférieur à <span class="math inline">\(2^{30}\)</span>, détermine le plus petit entier <span class="math inline">\(k\)</span> tel que <span class="math inline">\(n \le 2^k\)</span> :</p>
<p><div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="dt">int</span> plus_grande_puissance2(<span class="dt">int</span> n)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>{</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>    <span class="dt">int</span> k = <span class="dv">0</span>;</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>    <span class="dt">int</span> p = <span class="dv">1</span>;</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>    <span class="cf">while</span> (p &lt; n)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>    {</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>        k = k+<span class="dv">1</span>;</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>        p = p*<span class="dv">2</span>;</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>    }</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true"></a>    <span class="cf">return</span> k;</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p>On remarque que <code>p</code> prend successivement pour valeurs toutes les puissances de 2 jusqu’à une éventuelle sortie de boucle. Or, il existe une puissance de 2 supérieure ou égale à <code>n</code>, donc, une fois atteinte, la condition de la boucle <code>while</code> n’est plus remplie et l’algorithme termine.</p>
<h2 data-number="1.1" id="sec:variant-de-boucle"><span class="header-section-number">1.1</span> Variant de boucle</h2>
<p>Pour prouver la terminaison d’une boucle conditionnelle, on utilise un <strong>variant</strong> de boucle.</p>
<p><div class="ui message"><div class="header">Définition</div> Un <strong>variant de boucle</strong> est une quantité entière <strong>positive</strong> à l’entrée de chaque itération de la boucle et qui diminue <strong>strictement</strong> à chaque itération. </div></p>
<p>Ainsi, si on a un variant de boucle qui vaut initialement <span class="math inline">\(n\)</span> avant d’entrer dans la boucle, celle-ci effectue au plus <span class="math inline">\(n\)</span> itérations car le variant diminue au moins de 1 à chaque étape.</p>
<p>Si une boucle admet un variant de boucle, elle termine.</p>
<p>Dans l’exemple précédent, la quantité <span class="math inline">\(n-p\)</span> est un variant de boucle :</p>
<ul>
<li>Au départ, <span class="math inline">\(n &gt; 0\)</span> et <span class="math inline">\(p=1\)</span> donc <span class="math inline">\(n-p \ge 0\)</span></li>
<li>Comme il s’agit d’une différence de deux entiers, c’est un entier. Et tant que la condition de boucle est vérifiée <span class="math inline">\(p &lt; n\)</span> donc <span class="math inline">\(n-p &gt; 0\)</span>.</li>
<li>Lorsqu’on passe d’une itération à la suivante, la quantité passe de <span class="math inline">\(n-p\)</span> à <span class="math inline">\(n-2p\)</span> or <span class="math inline">\(2p-p &gt; 0\)</span> car <span class="math inline">\(p \ge 1\)</span>. Il y a bien une stricte diminution.</li>
</ul>
<p><div class="ui message orange"><div class="header">Remarque</div>Ici, en sortie de boucle, <span class="math inline">\(n-p \le 0\)</span>. On fait donc bien attention de préciser que la quantité est positive tant que la condition de boucle est vérifiée.</div></p>
<h2 data-number="1.2" id="sec:exemple-de-la-recherche-dichotomique"><span class="header-section-number">1.2</span> Exemple de la recherche dichotomique</h2>
<p>On considère ici la recherche dichotomique dans un tableau trié d’entiers. Étant donné un tableau <span class="math inline">\(t\)</span> de taille <span class="math inline">\(n &gt; 0\)</span> et un entier <span class="math inline">\(x\)</span> dont on cherche à déterminer sa présence dans le tableau entre les indices <span class="math inline">\(i\)</span> et <span class="math inline">\(j\)</span>, on considère l’algorithme suivant :</p>
<ul>
<li>Si <span class="math inline">\(i&gt;j\)</span>, alors il n’y a pas de sous-tableau et on renvoie <code>false</code>.</li>
<li>Sinon, soit <span class="math inline">\(m\)</span> l’élément d’indice <span class="math inline">\(p = \left\lfloor \frac{i+j}{2} \right\rfloor\)</span>.
<ul>
<li>Si <span class="math inline">\(x = m\)</span>, on renvoie <code>true</code></li>
<li>Si <span class="math inline">\(x &lt; m\)</span>, on continue la recherche dans le sous-tableau des indices <span class="math inline">\(i\)</span> à <span class="math inline">\(p-1\)</span>.</li>
<li>Si <span class="math inline">\(x &gt; m\)</span>, on continue la recherche dans le sous-tableau des indices <span class="math inline">\(p+1\)</span> à <span class="math inline">\(j\)</span>.</li>
</ul></li>
</ul>
<p>Le programme suivant présente une implémentation de cet algorithme en C.</p>
<p><div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="dt">int</span> rech_dicho(<span class="dt">int</span> *t, <span class="dt">size_t</span> n, <span class="dt">int</span> x)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>{</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>    <span class="co">/* renvoie un indice de x </span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a><span class="co">      si x est dans le tableau et -1 sinon */</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>    <span class="dt">size_t</span> i = <span class="dv">0</span>;</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>    <span class="dt">size_t</span> j = n-<span class="dv">1</span>;</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>    </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>    <span class="cf">while</span> (i &lt;= j) </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>    {</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a>        <span class="dt">size_t</span> p = i + (j-i)/<span class="dv">2</span>;</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a>        <span class="dt">int</span> m = t[p];</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a>        <span class="cf">if</span> (x == m)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true"></a>            <span class="cf">return</span> p;</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true"></a>        <span class="cf">else</span> <span class="cf">if</span> (x &lt; m)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true"></a>                j = p-<span class="dv">1</span>;</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true"></a>             <span class="cf">else</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true"></a>                i = p+<span class="dv">1</span>;</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true"></a>    }</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true"></a>    <span class="cf">return</span> -<span class="dv">1</span>;</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p><div class="ui message orange"><div class="header">Remarque</div>On a écrit <code>i+(j-i)/2</code> et non <code>(i+j)/2</code> afin d’éviter des erreurs de dépassement dans le calcul de <code>i+j</code>.</div></p>
<p>Ici, la terminaison n’est pas immédiate, on va la prouver à l’aide d’un variant de boucle. On considère ainsi la quantité <span class="math inline">\(d(i,j) = j-i\)</span>.</p>
<ul>
<li>Comme le tableau est non vide, <span class="math inline">\(d(0,n-1) \ge 0\)</span>. Ensuite, la condition de boucle est équivalente à <span class="math inline">\(d(i,j) \ge 0\)</span>, donc cette quantité est bien entière et positive à l’entrée de chaque itération.</li>
<li>Quand on passe à l’itération suivante, on passe
<ul>
<li>soit de <span class="math inline">\(d(i,j)\)</span> à <span class="math inline">\(d(i,p-1)\)</span>. Or <span class="math inline">\(d(i,j) - d(i,p-1) = j-i-\frac{i+j}{2}+1+i=1 + \frac{j-i}{2} = 1 + \frac{d(i,j)}{2} &gt; 0\)</span>.</li>
<li>soit de <span class="math inline">\(d(i,j)\)</span> à <span class="math inline">\(d(p+1,j)\)</span>. Or <span class="math inline">\(d(i,j) - d(p+1,j) = j-i-j+\frac{i+j}{2}+1+i=1 + \frac{j-i}{2} &gt;0\)</span>. Dans tous les cas, <span class="math inline">\(d(i,j)\)</span> diminue strictement.</li>
</ul></li>
</ul>
<p>Ainsi, il s’agit d’un variant de boucle et l’algorithme termine.</p>
<p><div class="ui message orange"><div class="header">Remarque</div>On remarque que le programme récursif suivant réalise également cet algorithme. <div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="co">(* rech_dicho : int array -&gt; int -&gt; int -&gt; int -&gt; int option *)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a><span class="kw">let</span> <span class="kw">rec</span> rech_dicho t i j x =</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>    <span class="kw">if</span> i &lt;= j</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>    <span class="kw">then</span> <span class="kw">let</span> p = (i+j)/<span class="dv">2</span> <span class="kw">in</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>         <span class="kw">let</span> m = t.(p) <span class="kw">in</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a>         <span class="kw">if</span> x = m</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a>         <span class="kw">then</span> <span class="dt">Some</span> p</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>         <span class="kw">else</span> <span class="kw">if</span> x &lt; m</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a>         <span class="kw">then</span> rech_dicho t i (p<span class="dv">-1</span>) x</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>         <span class="kw">else</span> rech_dicho t (p+<span class="dv">1</span>) j x</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a>    <span class="kw">else</span> <span class="dt">None</span></span></code></pre></div>
<p></div></p>
<p>Il suffit alors d’appeler <code>rech_dicho t 0 (Array.length t - 1) x</code> pour faire une recherche sur tout le tableau.</p>
<p>Ici, il n’y a pas explicitement de boucle mais le même principe peut être mis en place pour prouver que le nombre d’appel récursifs est majoré, et donc que toute exécution termine. En effet, la quantité <span class="math inline">\(d(i,j) = j-i\)</span> diminue pour les mêmes raisons à chaque appel récursif et reste entière positive.</div></p>
<h1 data-number="2" id="sec:correction"><span class="header-section-number">2</span> Correction</h1>
<p>Pour parler de correction d’un algorithme, il est nécessaire d’identifier précisément ce qui doit être calculé par l’algorithme. Pour cela, on considère ici informellement des spécifications dépendant des entrées et du résultat de l’algorithme. On verra dans le chapitre sur la logique qu’il s’agit ici de prédicats logiques.</p>
<p>Voici des exemples de spécifications :</p>
<ul>
<li>le tableau <span class="math inline">\(t\)</span> en sortie est trié dans l’ordre croissant</li>
<li>la valeur renvoyée est le plus petit indice de <span class="math inline">\(x\)</span> dans le tableau ou <span class="math inline">\(-1\)</span> s’il ne le contient pas.</li>
</ul>
<p><div class="ui message"><div class="header">Définition</div> Un algorithme est <strong>correct</strong> vis-à-vis d’une spécification lorsque quelle que soit l’entrée</p>
<ul>
<li>il <strong>termine</strong></li>
<li>le résultat renvoyé vérifie la spécification. </div></li>
</ul>
<p>On considère également la correction <strong>partielle</strong> en l’absence de terminaison :</p>
<p><div class="ui message"><div class="header">Définition</div> Un algorithme est <strong>partiellement correct</strong> vis-à-vis d’une spécification lorsque quelle que soit l’entrée le résultat renvoyé vérifie la spécification. </div></p>
<h2 data-number="2.1" id="sec:invariant-de-boucle"><span class="header-section-number">2.1</span> Invariant de boucle</h2>
<p><div class="ui message"><div class="header">Définition</div> On considère ici une boucle (conditionnelle ou non).</p>
<p>Un prédicat est appelé un <strong>invariant de boucle</strong> lorsque</p>
<ul>
<li>il est vérifié avant d’entrer dans la boucle</li>
<li>s’il est vérifié en entrée d’une itération, il est vérifié en sortie de celle-ci. </div></li>
</ul>
<p>Quand la boucle termine, on déduit alors que l’invariant est vérifié en sortie de boucle. On cherche donc un invariant qui permette de garantir la spécification en sortie de boucle.</p>
<p><div class="ui message orange"><div class="header">Remarque</div>Pour les boucles inconditionnelles, il y a une gestion implicite de l’indice de boucle qui va se retrouver dans l’invariant. On peut alors considérer que la sortie de boucle s’effectue après être passé à l’indice suivant.</div></p>
<p>Dans le cas d’une boucle conditionnelle portant sur la condition P et ayant un invariant de boucle I, en sortie le prédicat <span class="math inline">\(\neg P \wedge I\)</span> (non P et I) sera vérifié.</p>
<p>On peut illustrer cela en reprenant la fonction <code>plus_grande_puissance2</code> vue à la partie <a href="#sec:terminaison">Terminaison</a>. On considère ici le prédicat <span class="math inline">\(I(k,p) := 2^{k-1} &lt; n \text{ et } p = 2^k\)</span>.</p>
<ul>
<li>En entrée de boucle, on a bien <span class="math inline">\(2^{-1} &lt; n\)</span>.</li>
<li>Si le prédicat est vérifié en entrée d’itération. On a alors <span class="math inline">\(2^{k-1} &lt; n\)</span> et comme on est entrée dans cette itération <span class="math inline">\(p = 2^k &lt; n\)</span>. Donc en sortie d’itération on aura bien <span class="math inline">\(I(k+1,2p)\)</span> car <span class="math inline">\(2p = 2^{k+1}\)</span>.</li>
</ul>
<p>Ainsi, ce prédicat est bien un invariant et en sortie de boucle (ce qui arrive nécessairement car l’algorithme termine), le prédicat <span class="math inline">\(I(k,p)\)</span> signifie que <span class="math inline">\(2^{k-1} &lt; n\)</span> <strong>et la condition de sortie de boucle</strong> qu’on a <span class="math inline">\(n \le 2^k\)</span>.</p>
<p>La valeur renvoyée est bien <span class="math inline">\(k\)</span> tel que <span class="math inline">\(2^{k-1} &lt; n \le 2^k\)</span> ce qui était la spécification annoncée du programme.</p>
<h2 data-number="2.2" id="sec:exemple-du-tri-par-sélection"><span class="header-section-number">2.2</span> Exemple du tri par sélection</h2>
<p>Le programme suivant présente un algorithme de tri, appelé le <em>tri par sélection</em> dont on va analyser la complexité. Il s’agit d’un tri qui repose sur un principe simple, on va chercher le plus petit élément du tableau à trier et le placer à la position courante. On définit ainsi trois fonctions :</p>
<ul>
<li><code>echange</code> réalise l’échange de valeurs entre deux cases du tableau</li>
<li><code>indice_minimum</code> renvoie l’indice de la plus petite valeur entre deux indices donnés</li>
<li><code>tri_par_selection</code> réalise le tri en parcourant le tableau du premier au dernier indice et en plaçant à la position courante le minimum restant.</li>
</ul>
<p><div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="dt">void</span> echange(<span class="dt">int</span> *tableau, <span class="dt">int</span> i, <span class="dt">int</span> j)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>{</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>    <span class="dt">int</span> temp = tableau[i];</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>    tableau[i] = tableau[j];</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>    tableau[j] = temp;</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>}</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a><span class="dt">void</span> indice_minimum(<span class="dt">int</span> *tableau, <span class="dt">int</span> min_indice, <span class="dt">int</span> max_indice)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a>{</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a>    <span class="dt">int</span> i = min_indice;</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true"></a>    <span class="cf">for</span> (<span class="dt">int</span> j = min_indice + <span class="dv">1</span>; j &lt;= max_indice; j++)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true"></a>    {</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true"></a>        <span class="cf">if</span> (tableau[j] &lt; tableau[i])</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true"></a>            i = j;</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true"></a>    }</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true"></a>    <span class="cf">return</span> i;</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true"></a>}</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true"></a><span class="dt">void</span> tri_par_selection(<span class="dt">int</span> *tableau, <span class="dt">int</span> taille)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true"></a>{</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true"></a>    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; taille; i++)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true"></a>    {</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true"></a>        echange(tableau, i, indice_minimum(tableau, i, taille-<span class="dv">1</span>));</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true"></a>    }</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p>Il n’y a pas de problèmes de terminaison ici car toutes les boucles sont inconditionnelles. Pour prouver sa correction, on va considérer séparément les deux boucles.</p>
<ul>
<li>Boucle dans <code>indice_minimum</code> : on va valider l’invariant <span class="math inline">\(I(i,j) := \forall k \in \range{i}{j-1}, \text{tableau}[i] \le \text{tableau}[k]\)</span>.
<ul>
<li>En entrée de boucle, on a <span class="math inline">\(I(\text{min\_indice},\text{min\_indice}+1)\)</span> vérifié directement.</li>
<li>Si en entrée d’itération, <span class="math inline">\(I(i,j)\)</span> est vérifié, ce qui signifie que <span class="math inline">\(\text{tableau}[i]\)</span> est plus petit que les valeurs compris entre les indices <span class="math inline">\(i\)</span> et <span class="math inline">\(j-1\)</span>. Alors, on distingue deux cas :
<ul>
<li>soit <span class="math inline">\(\text{tableau}[j] &lt; \text{tableau}[i]\)</span> et alors en sortie <span class="math inline">\(i\)</span> devient <span class="math inline">\(i&#39; = j\)</span>. On a alors <span class="math inline">\(\text{tableau}[i&#39;] = \text{tableau}[j] &lt; \text{tableau}[i] \le \text{tableau}[k]\)</span> pour <span class="math inline">\(k \in \range{1}{j-1}\)</span>. Donc <span class="math inline">\(I(i&#39;,j+1)\)</span> est vérifié.</li>
<li>soit <span class="math inline">\(\text{tableau}[i] \le \text{tableau}[j]\)</span> et ainsi on a pu prolonger le prédicat à <span class="math inline">\(I(i,j+1)\)</span>.</li>
</ul></li>
</ul>
Ce prédicat est bien un invariant. Ainsi, en sortie de boucle, et donc avant de renvoyer sa valeur, on a bien <span class="math inline">\(I(i,\text{taille})\)</span> donc <span class="math inline">\(\text{tableau}[i]\)</span> est la plus petite valeur du tableau.</li>
<li>Boucle dans <code>tri_par_selection</code> : on va valider l’invariant $T(i) := $ le sous-tableau <code>tableau[0..i-1]</code> des indices 0 à <span class="math inline">\(i-1\)</span> est trié et ne contient que des valeurs plus petites que celles du sous-tableau <code>tableau[i..taille-1]</code>.
<ul>
<li>En entrée de boucle, le sous-tableau est vide donc trié.</li>
<li>Si en entrée d’itération, le prédicat est vérifié. On récupère l’indice <span class="math inline">\(j\)</span> du minimum du sous-tableau <code>tableau[i..taille-1]</code> à l’aide la fonction <code>indice_minimum</code>, par hypothèse <code>tableau[j]</code> est alors supérieur ou égal à chaque élément de <code>tableau[0..i-1]</code>, en le plaçant à l’indice i, on a bien <code>tableau[0..i]</code> qui est trié et par construction la valeur de <code>tableau[i]</code> est inférieure à toutes celels de <code>tableau[i+1..taille-1]</code>. On a ainsi <span class="math inline">\(T(i+1)\)</span> vérifié en sortie d’itération.</li>
</ul>
Ce prédicat est bien un invariant. Ainsi, en sortie de boucle, <span class="math inline">\(T(\text{taille})\)</span> est vérifié : le tableau est trié.</li>
</ul>
<h1 data-number="3" id="sec:complexité"><span class="header-section-number">3</span> Complexité</h1>
<h2 data-number="3.1" id="sec:complexité-dans-le-pire-des-cas"><span class="header-section-number">3.1</span> Complexité dans le pire des cas</h2>
<p>Considérons un algorithme pour lequel on peut associer à chaque entrée une notion de taille (par exemple le nombre d’éléments d’un tableau). Pour <span class="math inline">\(n \in \N\)</span>, on note ainsi <span class="math inline">\(I_n\)</span> l’ensemble des entrées de taille <span class="math inline">\(n\)</span> pour cet algorithme. Pour une entrée <span class="math inline">\(e\)</span>, on note <span class="math inline">\(t(e)\)</span> le temps pris, par exemple en seconde, par l’algorithme sur l’entrée <span class="math inline">\(e\)</span>. De même, on note <span class="math inline">\(s(e)\)</span> l’espace mémoire maximal, par exemple en octets, occupé par l’algorithme au cours de cette exécution <strong>sans compter la taille des entrées</strong>.</p>
<p><div class="ui message"><div class="header">Définition</div> On appelle :</p>
<ul>
<li><strong>complexité temporelle dans le pire des cas</strong>, la suite <span class="math inline">\((C^t_n)_{n \in \N}\)</span> telle que pour tout <span class="math inline">\(n \in \N\)</span>, <span class="math inline">\(C^t_n = \max_{e \in I_n} t(e)\)</span>.</li>
<li><strong>complexité spatiale dans le pire des cas</strong>, la suite <span class="math inline">\((C^s_n)_{n \in \N}\)</span> telle que pour tout <span class="math inline">\(n \in \N\)</span>, <span class="math inline">\(C^s_n = \max_{e \in I_n} s(e)\)</span>. </div></li>
</ul>
<p>Comme on va le voir, calculer explicitement ces suites n’a pas beaucoup d’intérêt tant elles sont dépendantes de la manière dont on mesure le temps et l’espace. Ce qui compte ici, c’est de connaître l’<em>ordre de grandeur</em> de ces complexités en fonction de <span class="math inline">\(n\)</span>.</p>
<p><div class="ui internally celled grid"><div class="row"><div class="eight wide column"> Pour un tableau de taille <span class="math inline">\(n\)</span>, ce programme va effectuer <span class="math inline">\(n\)</span> itérations et sa complexité est ainsi de l’ordre de <span class="math inline">\(n\)</span>. Il est possible d’être très précis en considérant les temps pris</p>
<ul>
<li>pour mettre en place l’appel de fonction et le passage des arguments</li>
<li>par la gestion de l’indice de la boucle for</li>
<li>pour la comparaison, puis pour l’affectation éventuelle</li>
<li>pour mettre en place la valeur de retour afin que le résultat soit lu</li>
</ul>
<p>On peut remarquer que la notion de pire cas dépend de la précision à laquelle on se place. Ici, si on ne s’intéresse qu’à l’ordre de grandeur, tous les tableaux de taille <span class="math inline">\(n\)</span> sont équivalents. Par contre, si on cherche avec précision le pire cas, il est atteint avec un tableau trié par ordre croissant car c’est le cas qui effectue une affectation à chaque itération. </div><div class="eight wide column"> <div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="dt">int</span> maximum(<span class="dt">int</span> *tableau, <span class="dt">int</span> taille)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a>{</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>    <span class="dt">int</span> M = INT_MIN;</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a>    <span class="cf">for</span>(<span class="dt">int</span> i=<span class="dv">0</span>; i&lt;taille; i++) </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a>    {</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>        <span class="cf">if</span> (M &gt; tableau[i])</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>            M = tableau[i];</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a>    }</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a>    <span class="cf">return</span> M;</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p></div></div></div></p>
<h2 data-number="3.2" id="sec:comparer-des-complexités"><span class="header-section-number">3.2</span> Comparer des complexités</h2>
<p>Avant de pouvoir comparer les complexités des algorithmes ou des programmes, il est nécessaire de mettre en place des outils pour en parler à la fois avec précision mais également sans rentrer dans des détails inextricables d’implémentation.</p>
<p>En effet, comparons les deux fonctions suivantes permettant de calculer le maximum d’un tableau non vide :</p>
<p><div class="ui internally celled grid"><div class="row"><div class="eight wide column"> <div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="dt">int</span> maximum(<span class="dt">int</span> *tableau, <span class="dt">int</span> taille)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>{</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>    <span class="dt">int</span> M = INT_MIN;</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true"></a>    <span class="cf">for</span>(<span class="dt">int</span> i=<span class="dv">0</span>; i&lt;taille; i++) </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true"></a>    {</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true"></a>        <span class="cf">if</span> (M &gt; tableau[i])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true"></a>            M = tableau[i];</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true"></a>    }</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true"></a>    <span class="cf">return</span> M;</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p></div><div class="eight wide column"> <div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="dt">int</span> maximum(<span class="dt">int</span> *tableau, <span class="dt">int</span> taille)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a>{</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a>    <span class="dt">int</span> M = tableau[<span class="dv">0</span>];</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true"></a>    <span class="cf">for</span>(<span class="dt">int</span> i=<span class="dv">1</span>; i&lt;taille; i++) </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true"></a>    {</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true"></a>        <span class="cf">if</span> (M &gt; tableau[i])</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true"></a>            M = tableau[i];</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true"></a>    }</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true"></a>    <span class="cf">return</span> M;</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p></div></div></div></p>
<p>La fonction de gauche semble moins efficace que celle de droite car elle effectue une itération de boucle de moins. Mais on doit se poser la question de la pertinence de cette optimisation selon la taille du tableau.</p>
<p>De la même manière, il faut déterminer ce que l’on souhaite compter précisément :</p>
<ul>
<li>si on s’intéresse au temps mis, certaines opérations prennent moins de temps que d’autre (par exemple une addition par rapport à une multiplication) mais est-ce vraiment important à l’échelle considérée ?</li>
<li>si on s’intéresse à l’espace mémoire, doit-on considérer la taille précise en octets ou se contenter d’une estimation plus grossière ?</li>
</ul>
<p>Mis à part dans certains cadres assez spécifiques, on se contente le plus souvent d’un ordre de grandeur pour ces complexité. Pour cela, on utilise des relations de comparaisons de suites et une échelle de grandeur usuelle pour les comparer.</p>
<p><div class="ui message blue"><div class="header">Note</div>Redite ici avec la partie précédente. A reprendre.</div></p>
<h3 data-number="3.2.1" id="sec:la-notation-grand-o"><span class="header-section-number">3.2.1</span> La notation grand O</h3>
<p><div class="ui message"><div class="header">Définition</div> Soit <span class="math inline">\((u_n)_{n\in\N}\)</span> et <span class="math inline">\((v_n)_{n \in \N}\)</span> deux suites de nombres réels non nuls, on dit que la suite <span class="math inline">\((u_n)_n\)</span> est dominée par <span class="math inline">\((v_n)_n\)</span> lorsque la suite quotient <span class="math inline">\(\left( \frac{u_n}{v_n} \right)_n\)</span> est bornée.</p>
<p>On note alors <span class="math inline">\(u_n = O(v_n)\)</span>. </div></p>
<p>Cette dernière notation se lit <em><span class="math inline">\(u_n\)</span> est un grand O de <span class="math inline">\(v_n\)</span></em>.</p>
<p><div class="ui message orange"><div class="header">Remarque</div>C’est bien cette locution qu’il faut avoir en tête quand on pense aux grands O et il faut faire attention de ne pas considérer l’égalité en tant que telle sans s’assurer que ce l’on fait est licite. Quand on écrira par la suite <span class="math inline">\(O(v_n)\)</span> on signifiera <em>n’importe quelle suite qui soit un <span class="math inline">\(O(v_n)\)</span></em>.</div></p>
<p>Si <span class="math inline">\(u_n = O(v_n)\)</span>, cela signifie qu’il existe un facteur <span class="math inline">\(M &gt; 0\)</span> tel que pour tout entier <span class="math inline">\(n\)</span>, on ait <span class="math inline">\(- M |v_n| \le u_n \le M |v_n|\)</span>. Les variations de la suite <span class="math inline">\((u_n)_n\)</span> sont ainsi entièrement contrôlées par les variations de <span class="math inline">\((v_n)_n\)</span>.</p>
<p>En informatique, on ne considère pour la complexité que des suites positives, ce qui permet de simplifier la relation : si <span class="math inline">\((u_n)_n, (v_n)_n\)</span> sont des suites de réels strictement positifs, alors <span class="math inline">\(u_n = O(v_n) \iff \exists M &gt; 0, \forall n\in\N, u_n \le M v_n\)</span>. C’est le cadre dans lequel on se place implicitement dans la suite de ce document.</p>
<p>On peut visualiser graphiquement cette relation :</p>
<p><div class="ui internally celled grid"><div class="row"><div class="eight wide column"> <img src="assets/pics/grando_ex1.png" /></p>
<p></div><div class="eight wide column"> On a <span class="math inline">\(u_n = O(v_n)\)</span> si et seulement s’il est possible de multiplier les ordonnés de chaque point <span class="math inline">\((n,v_n)\)</span> par une constante afin que ces nouveaux points soient tous au-dessus des points <span class="math inline">\((n,u_n)\)</span>. On peut voir que la courbe déduite des <span class="math inline">\(v_n\)</span> enveloppe, à un facteur près, celle des <span class="math inline">\(u_n\)</span>.</p>
<p><strong>Remarque:</strong> <em>On a relié ici les valeurs des suites pour mieux mettre en valeur cette notion d’enveloppe.</em> </div></div></div></p>
<p>Cette relation est une notion <strong>asymptotique</strong> : elle n’a d’intérêt que lorsqu’on considère des rangs au voisinage de l’infini. En effet, pour un nombre fini de termes, il est toujours possible de trouver un tel <span class="math inline">\(M\)</span>, mais pour un nombre infini, ce n’est pas le cas.</p>
<p><div class="ui internally celled grid"><div class="row"><div class="nine wide column"> <img src="assets/pics/grando_ex2.png" /></p>
<p></div><div class="six wide column"> Ici, on compare asymptotiquement les suites <span class="math inline">\((u_n)_n\)</span> et <span class="math inline">\((v_n)_n\)</span> où pour <span class="math inline">\(n \in \N\)</span>, <span class="math inline">\(u_n = n + n \log_2 n\)</span> et <span class="math inline">\(v_n = n \log_2 n\)</span>. Pour simplifier la visualisation, on a tracé les fonctions correspondantes. On remarque qu’on a bien <span class="math inline">\(n + n \log_2 n = O(n \log_2 n)\)</span>. </div></div></div></p>
<p><div class="ui internally celled grid"><div class="row"><div class="nine wide column"> <img src="assets/pics/grando_ex3.png" /></p>
<p></div><div class="six wide column"> Par contre, si on compare les suites <span class="math inline">\((u_n)_n\)</span> et <span class="math inline">\((v_n)_n\)</span> où pour <span class="math inline">\(n \in \N\)</span>, <span class="math inline">\(u_n = n^2\)</span> et <span class="math inline">\(v_n = n \log_2 n\)</span>, on remarque que quelle que soit la valeur choisie pour <span class="math inline">\(M\)</span>, il y aura un rang à partir duquel <span class="math inline">\(u_n &gt; M v_n\)</span>.</p>
<p>Ici, <span class="math inline">\(n^2 \not = O(n \log_2 n)\)</span>. </div></div></div></p>
<p><div class="ui message orange"><div class="header">Remarque</div>On a ici utilisé le logarithme en base 2, noté <span class="math inline">\(\log_2\)</span>, qui est essentiel informatique : si <span class="math inline">\(x = \log_2(n)\)</span> alors <span class="math inline">\(n = 2^x\)</span> où <span class="math inline">\(x\)</span> est un réel. On considère aussi <span class="math inline">\(p = \lceil \log_2(n) \rceil\)</span> qui est le plus petit entier égal ou supérieur à <span class="math inline">\(\log_2(n)\)</span>. On parle de <strong>partie entière supérieure</strong> et on a alors <span class="math inline">\(2^{p-1} &lt; n \le 2^p\)</span>. Cet entier <span class="math inline">\(p\)</span> correspond alors au plus petit nombre de chiffre nécessaire pour pouvoir écrire <span class="math inline">\(n\)</span> en binaire. On a <span class="math inline">\(\lceil \log_2(n) \rceil = O(\log_2(n))\)</span> et ainsi, le plus souvent, on ne considère pas la partie entière explicitement. De la même manière, <span class="math inline">\(\log_2(n) = \frac{\ln n}{\ln 2} = O(\ln n)\)</span>.</div></p>
<p>Un cas important de grand O est celui des <span class="math inline">\(O(1)\)</span>. Si <span class="math inline">\(u_n = O(1)\)</span>, cela signifie que <span class="math inline">\((u_n)_{n\in\N}\)</span> est une suite bornée.</p>
<h3 data-number="3.2.2" id="sec:échelle-de-comparaison"><span class="header-section-number">3.2.2</span> Échelle de comparaison</h3>
<p>On rappelle les limites obtenues en mathématiques que l’on nomme <strong>croissances comparées</strong> :</p>
<p><span class="math display">\[
\forall \alpha,\beta &gt; 0, \lim_{n \rightarrow +\infty} \frac{(\ln n)^\alpha}{n^\beta} = 0 
\qquad
\lim_{n \rightarrow +\infty} \frac{n^\alpha}{\beta^n} = 0 
\]</span></p>
<p>Or, si <span class="math inline">\(\frac{u_n}{v_n} \tend{n}{+\infty} 0\)</span> <em>a fortiori</em> le quotient est borné et <span class="math inline">\(u_n = O(v_n)\)</span>. Ainsi, on a les relations suivantes :</p>
<p><span class="math display">\[
\forall \alpha,\beta &gt; 0, 
(\log_2 n)^\alpha = O(n^\beta) \qquad
n^\alpha = O(\beta^n)
\]</span> De plus, si <span class="math inline">\(\alpha \ge \beta &gt; 0\)</span>, <span class="math inline">\(n^\beta = O(n^\alpha)\)</span>, <span class="math inline">\((\log_2 n)^\beta = O((\log_2 n)^\alpha)\)</span> et <span class="math inline">\(\beta^n = O(\alpha^n)\)</span>.</p>
<p>On se ramène souvent à des complexités qui sont des grand O de produits de ces suites.</p>
<h3 data-number="3.2.3" id="sec:ordre-de-grandeur-et-relation-theta"><span class="header-section-number">3.2.3</span> Ordre de grandeur et relation <span class="math inline">\(\Theta\)</span></h3>
<p>On vient de voir que <span class="math inline">\(\log_2 n = O(n)\)</span>, mais on a également <span class="math inline">\(\log_2 = O(n^2)\)</span>. Quand on cherche à caractériser la complexité par un grand O, on va souvent chercher le grand O le plus proche de la suite.</p>
<p>Il est possible de définir cela précisément en considérant des suites qui sont chacune des grand O l’une de l’autre.</p>
<p>Par exemple, on a vu que <span class="math inline">\(n \log_2 n + n = O(n \log_2 n)\)</span>, mais on a également <span class="math inline">\(n \log_2 n = O(n + n \log_2 n)\)</span>.</p>
<p>Quand <span class="math inline">\(u_n = O(v_n)\)</span> et <span class="math inline">\(v_n = O(u_n)\)</span>, on note <span class="math inline">\(u_n = \Theta(v_n)\)</span> qui est une relation symétrique qui correspond à la notion <em>avoir le même ordre de grandeur</em>. Très souvent, lorsque l’on parle de complexité, on utilise des grand O quand, en fait, on exprime des <span class="math inline">\(\Theta\)</span>. Par exemple, l’accès à un élément dans un tableau est en <span class="math inline">\(O(1)\)</span> et il ne serait pas précis de dire que c’est en <span class="math inline">\(O(n)\)</span> <strong>même si c’est parfaitement correct</strong>.</p>
<p>On peut visualiser cette relation <span class="math inline">\(\Theta\)</span> en considérant qu’il existe ainsi <span class="math inline">\(M,M&#39; &gt; 0\)</span> tels que <span class="math inline">\(u_n \le M v_n\)</span> et <span class="math inline">\(v_n \le M&#39; u_n\)</span>. Mais on a alors <span class="math display">\[
1/M&#39; v_n \le u_n \le M v_n
\]</span> Ainsi, <span class="math inline">\(u_n = \Theta(v_n)\)</span> signifie qu’on peut encadrer <span class="math inline">\((u_n)_n\)</span> entre deux multiples de <span class="math inline">\((v_n)_n\)</span>.</p>
<p><div class="ui internally celled grid"><div class="row"><div class="nine wide column"> <img src="assets/pics/grando_theta.png" /></p>
<p></div><div class="six wide column"> En reprenant la figure précédente, on observe visuellement <span class="math display">\[n \log_2 n \le n \log_2 n + n \le 2 n \log_2 n\]</span> </div></div></div></p>
<p>Avoir <span class="math inline">\(u_n = \Theta(v_n)\)</span> signifie donc que <span class="math inline">\(u_n\)</span> évolue entre deux guides suivant les variations de <span class="math inline">\(v_n\)</span>.</p>
<h3 data-number="3.2.4" id="sec:opérations-sur-les-grands-o"><span class="header-section-number">3.2.4</span> Opérations sur les grands O</h3>
<p>Si <span class="math inline">\(u_n = O(w_n)\)</span> et <span class="math inline">\(v_n = O(w_n)\)</span> alors <span class="math inline">\(u_n + v_n = O(w_n)\)</span>. Ainsi, des grand O de même ordre s’ajoutent.</p>
<p><div class="ui message orange"><div class="header">Remarque</div>Comme on l’a vu précédemment, un grand O n’est pas très précis, et il est possible que par ajout on puisse obtenir un meilleur grand O. Par exemple : <span class="math inline">\(n = O(n)\)</span> et <span class="math inline">\(\log_2 n - n = O(n)\)</span> mais <span class="math inline">\(n + \log_2 n - n = \log_2 n = O(n)\)</span>. Comme on ne considère ici que des suites strictement positifs, ce phénomène de compensation n’aura pas lieu.</div></p>
<p>Si <span class="math inline">\(u_n = O(v_n)\)</span> et <span class="math inline">\(w_n\)</span> est une autre suite de réels strictement positifs, alors <span class="math inline">\(u_n w_n = O(v_n w_n)\)</span>. On en déduit ainsi un principe qui nous sera utile par la suite <span class="math inline">\(n O(1) = O(n)\)</span>.</p>
<h2 data-number="3.3" id="sec:complexités-en-temps-classiques"><span class="header-section-number">3.3</span> Complexités en temps classiques</h2>
<p>On parle ici de complexité par raccourci pour parler de complexité dans le pire des cas en temps.</p>
<p><div class="ui message blue"><div class="header">Note</div>Pas convaincu de l’intérêt de ce raccourci par rapport à l’imprécision qui en résulte sur un chapitre d’introduction.</div></p>
<h3 data-number="3.3.1" id="sec:complexité-constante"><span class="header-section-number">3.3.1</span> Complexité constante</h3>
<p>On dit qu’un algorithme a une complexité constante quand <span class="math inline">\(C^t_n = O(1)\)</span>. Il existe ainsi une constante <span class="math inline">\(M\)</span> telle que le temps pris par l’algorithme <strong>sur une entrée quelconque</strong> soit inférieur à <span class="math inline">\(M\)</span>.</p>
<p>De nombreuses opérations sont en temps constant sur les structures de données usuelles. Parmi celles-ci, citons-en deux essentielles :</p>
<ul>
<li>accéder à une case d’indice quelconque dans un tableau</li>
<li>accéder à la tête ou à la queue d’une liste chaînée</li>
</ul>
<p>Les algorithmes ou opérations en temps constant jouent un rôle primordiale dans l’analyse de la complexité d’algorithmes, comme on le verra dans la partie suivante, car elles permettent de se concentrer sur les répétitions de ces opérations pour déterminer la complexité : une boucle qui se répète <span class="math inline">\(n\)</span> fois et n’effectue que des opérations en temps constant dans son corps sera de complexité <span class="math inline">\(n O(1) = O(n)\)</span>.</p>
<h3 data-number="3.3.2" id="sec:complexité-linéaire"><span class="header-section-number">3.3.2</span> Complexité linéaire</h3>
<p>On dit qu’un algorithme a une complexité linéaire quand <span class="math inline">\(C^t_n = O(n)\)</span>.</p>
<p>Cette complexité correspond à un traitement de temps constant sur chaque élément d’une entrée de taille <span class="math inline">\(n\)</span>. C’est le cas de la recherche d’un élément dans un tableau ou de la recherche de son maximum.</p>
<p><div class="ui internally celled grid"><div class="row"><div class="eight wide column"> Pour la recherche linéaire d’un élément, correspondant par exemple au programme ci-contre, le pire cas correspond à ne pas avoir <code>x</code> dans <code>tableau</code> ce qui oblige à effectuer toutes les itérations. On a bien une complexité temporelle en pire cas de <span class="math inline">\(O(n)\)</span>. </div><div class="eight wide column"> <div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a><span class="dt">int</span> recherche(<span class="dt">int</span> *tableau, <span class="dt">int</span> taille, <span class="dt">int</span> x)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a>{</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a>    <span class="co">/* renvoie le plus petit indice i tel que tableau[i] = x</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a><span class="co">       ou -1 si x n&#39;est pas dans le tableau */</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a>    <span class="cf">for</span>(<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; taille; i++)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true"></a>    {</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true"></a>        <span class="cf">if</span> (tableau[i] == x)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true"></a>            <span class="cf">return</span> i;</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true"></a>    }</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true"></a>    <span class="cf">return</span> -<span class="dv">1</span>;</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p></div></div></div></p>
<h3 data-number="3.3.3" id="sec:complexité-quadratique-polynomiale"><span class="header-section-number">3.3.3</span> Complexité quadratique, polynomiale</h3>
<p>On dit qu’un algorithme a une complexité quadratique quand <span class="math inline">\(C^t_n = O(n^2)\)</span>. Par extension, on dit qu’il a une complexité polynomiale quand il existe <span class="math inline">\(k \in \N\)</span> tel que <span class="math inline">\(C^t_n = O(n^k)\)</span>. Par extension, on parle parfois de complexité polynomiale pour des complexité plus précise en <span class="math inline">\(O(n^\alpha)\)</span> où <span class="math inline">\(\alpha\)</span> est un réel strictement positif.</p>
<p>L’exemple classique d’un algorithme quadratique est celui dû à un double parcours d’un tableau. On reprend ici l’algorithme de tri par sélection vu dans la partie <a href="#sec:exemple-du-tri-par-sélection">Exemple du tri par sélection</a>.</p>
<p>Afin d’analyser sa complexité, on procède fonction par fonction pour un tableau de taille <span class="math inline">\(n\)</span> :</p>
<ul>
<li><code>echange</code> est en temps constant. <span class="math inline">\(O(1)\)</span></li>
<li><code>indice_minimum</code> réalise un parcours du tableau et effectue des opérations en temps constant à chaque étape. La complexité est donc linéaire. <span class="math inline">\(O(n)\)</span></li>
<li><code>tri_par_selection</code> réalise également un parcours du tableau mais à chaque étape, on appelle <code>indice_minimum</code> qui est en <span class="math inline">\(O(n)\)</span>, la complexité est donc en <span class="math inline">\(n O(n) = O(n^2)\)</span> : elle est quadratique.</li>
</ul>
<h3 data-number="3.3.4" id="sec:complexité-logarithmique"><span class="header-section-number">3.3.4</span> Complexité logarithmique</h3>
<p>On dit qu’un algorithme a une complexité logarithmique quand <span class="math inline">\(C_n^t = O(\log_2 n)\)</span>.</p>
<p>Pour illustrer cette complexité, on reprend l’algorithme de recherche dichotomique vu dans la partie <a href="#sec:exemple-de-la-recherche-dichotomique">Exemple de la recherche dichotomique</a>.</p>
<p>Chaque opération effectuée étant en temps constant, la complexité de cet algorithme correspond au nombre d’itérations, soit ici au nombre d’appels récursifs.</p>
<p>Si on considère un sous-tableau de <span class="math inline">\(n = j-i+1\)</span> éléments lors de l’appel, un appel récursif se fera nécessairement sur un sous-tableau de <span class="math inline">\(\lfloor n/2 \rfloor\)</span> éléments. Ainsi, si <span class="math inline">\(2^{k-1} &lt; n \le 2^k\)</span>, l’algorithme effectue moins de <span class="math inline">\(k\)</span> itérations. En passant au logarithme, on a donc <span class="math inline">\(k-1 &lt; \log_2 n \le k\)</span>. Donc, le nombre d’itérations est en <span class="math inline">\(O(\log_2 n)\)</span> et c’est ainsi la complexité de l’algorithme.</p>
<p><div class="ui message blue"><div class="header">Note</div>Esquisser dès maintenant le lien entre longueur d’une branche dans un arbre de décision et complexité logarithmique ?</div></p>
<h3 data-number="3.3.5" id="sec:complexité-quasi-linéaire"><span class="header-section-number">3.3.5</span> Complexité quasi-linéaire</h3>
<p>On dit qu’un algorithme a une complexité quasi-linéaire quand <span class="math inline">\(C^t_n = O(n \log_2 n)\)</span>. C’est le cas de la plupart des algorithmes efficaces de tri de <span class="math inline">\(n\)</span> éléments. On peut même montrer qu’il s’agit de la complexité optimale.</p>
<p>Comme de nombreux algorithmes commencent par effectuer un tri avant d’effectuer un traitement linéaire, on retrouve des algorithmes quasi-linéaire par simple utilisation de ce tri.</p>
<h3 data-number="3.3.6" id="sec:complexité-exponentielle"><span class="header-section-number">3.3.6</span> Complexité exponentielle</h3>
<p>On dit qu’un algorithme a une complexité exponentielle quand <span class="math inline">\(C^t_n = O(a^n)\)</span> pour <span class="math inline">\(a &gt; 0\)</span>.</p>
<p>Un exemple fondamental d’un tel algorithme est celui de l’énumération de données, par exemple pour chercher une solution par force brute. En effet, il y a <span class="math inline">\(2^n\)</span> entrées codées sur <span class="math inline">\(n\)</span> bits et un algorithme cherchant une solution ainsi parmi ces entrées aura une complexité en <span class="math inline">\(O(2^n)\)</span>.</p>
<h3 data-number="3.3.7" id="sec:estimation-de-limpact-des-complexités-sur-le-temps"><span class="header-section-number">3.3.7</span> Estimation de l’impact des complexités sur le temps</h3>
<p>Afin de mesurer l’impact d’une complexité, on va considérer un algorithme qui s’exécute en 1 seconde sur un entrée de taille <span class="math inline">\(n\)</span>, et on va calculer combien de temps prendrait ce même algorithme sur une entrée de taille <span class="math inline">\(10 n\)</span>.</p>
<p>Pour simplifier, on considère à chaque fois que <span class="math inline">\(C^t_n\)</span> correspond exactement à l’ordre du grand O.</p>
<table>
<thead>
<tr class="header">
<th>Complexité</th>
<th>Temps pour 10n</th>
<th>Temps pour 100n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1s</td>
<td>1s</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\log_2 n\)</span></td>
<td>1,003s</td>
<td>1,007s</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n\)</span></td>
<td>10s</td>
<td>1m40s</td>
</tr>
<tr class="even">
<td><span class="math inline">\(n \log_2 n\)</span></td>
<td>14,7s</td>
<td>3m13s</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n^2\)</span></td>
<td>1m40s</td>
<td>2h46m40s</td>
</tr>
<tr class="even">
<td><span class="math inline">\(2^n\)</span></td>
<td><span class="math inline">\(10^{19}\)</span> années</td>
<td><span class="math inline">\(10^{289}\)</span> années.</td>
</tr>
</tbody>
</table>
<p><div class="ui message orange"><div class="header">Remarque</div>Pour déterminer ces valeurs, on a considéré une unité de mesure de 1000ms afin d’en déduire une valeur de <span class="math inline">\(n\)</span>.</p>
<p>Ainsi, si <span class="math inline">\(\log_2 n = 1000\)</span> on a <span class="math inline">\(n = 2^{1000}\)</span>. Bien sûr, ici, ce nombre <span class="math inline">\(2^{1000}\)</span> n’est pas réaliste. Dans un contexte de mémoire finie, une complexité logarithmique est identifiable à une complexité constante. Cela justifie la terminologie quasi-linéaire.</p>
<p>Si <span class="math inline">\(n \log_2 n = 1000\)</span> alors <span class="math inline">\(n \approx 140,2\)</span>. Or, <span class="math inline">\(1402 \log_2 1402 \approx 14700ms\)</span>.</p>
<p>Si <span class="math inline">\(2^n = 1000\)</span>, alors <span class="math inline">\(n \approx 10\)</span>. Or <span class="math inline">\(2^{100} \approx 10^{30}\)</span>. </div></p>
<h2 data-number="3.4" id="sec:calculer-des-complexités"><span class="header-section-number">3.4</span> Calculer des complexités</h2>
<p>Deux principes fondamentaux pour calculer des complexités :</p>
<ul>
<li>Si on effectue deux passes successives chacune en <span class="math inline">\(O(u_n)\)</span> alors la complexité globale est en <span class="math inline">\(O(u_n)\)</span>. Il ne s’agit que de reformuler l’addition des grand O. Quand on a deux passes de complexité différente, il suffit d’utiliser la plus grande complexité. Par exemple, un algorithme qui commence par un tri en <span class="math inline">\(O(n \log_2 n)\)</span> et qui effectue ensuite un traitement en <span class="math inline">\(O(n)\)</span> sera de complexité globale <span class="math inline">\(O(n \log_2 n)\)</span> car le traitement est également en <span class="math inline">\(O(n \log_2 n)\)</span>.</li>
<li>Si on effectue <span class="math inline">\(u_n\)</span> itérations et que chaque itération est en <span class="math inline">\(O(v_n)\)</span> alors l’algorithme a une complexité de <span class="math inline">\(O(u_n v_n)\)</span>. Cela permet de compter le nombre de boucles imbriquées et de se contenter de regarder ce qui se passe dans le corps des boucles.</li>
</ul>
<h2 data-number="3.5" id="sec:complexité-à-plusieurs-paramètres"><span class="header-section-number">3.5</span> Complexité à plusieurs paramètres</h2>
<p>Jusqu’ici on a considéré des entrées dépendant d’un unique paramètre <span class="math inline">\(n\)</span>, mais il est possible d’avoir des données dépendant de plusieurs paramètres.</p>
<p>On adapte directement la notation des grands O : si <span class="math inline">\((u_{n,p})\)</span> et <span class="math inline">\((v_{n,p})\)</span> sont deux suites de réels non nuls dépendant de deux paramètres, on note toujours <span class="math inline">\(u_{n,p} = O(v_{n,p})\)</span> quand le quotient est borné.</p>
<h3 data-number="3.5.1" id="sec:données-multidimensionnelles"><span class="header-section-number">3.5.1</span> Données multidimensionnelles</h3>
<p>Le cas le plus usuel de complexité dépendant de plusieurs paramètres est celui des données multidimensionnelle comme une image.</p>
<p>Si on considère une opération effectuant un traitement en temps constant sur chaque pixel d’une image de <span class="math inline">\(w \times h\)</span> pixels, cette opération aura une complexité en <span class="math inline">\(O(w h)\)</span>. On ne peut plus parler de complexité linéaire ou quadratique ici car cela dépend d’une éventuelle relation entre w et h : si on ne travaille que sur des images de taille <span class="math inline">\(1 \times h\)</span> alors la complexité est <span class="math inline">\(O(h)\)</span>, mais on ne travaille que sur des images carrées, donc pour lesquelles <span class="math inline">\(w = h\)</span>, la complexité est <span class="math inline">\(O(h^2)\)</span>.</p>
<p>Plus généralement, si on considère des données organisées dans des tableaux imbriqués, on effectuera un traitement sur chaque donnée à l’aide de boucles imbriquées non conditionnelles. La complexité sera alors celle du corps de boucles multipliée par le produit du nombre d’itérations de chaque boucle.</p>
<h3 data-number="3.5.2" id="sec:compromis-entre-paramètres"><span class="header-section-number">3.5.2</span> Compromis entre paramètres</h3>
<p>Dans certains cas, en particulier pour les graphes, on peut effectuer des traitements successifs dont la complexité ne s’exprime pas en fonction du même paramètre. Imaginons par exemple un programme ayant la structure suivante :</p>
<p><div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a><span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i&lt;n; i++)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true"></a>{</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true"></a>    <span class="co">/* corps de boucle en O(1) */</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true"></a>}</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true"></a><span class="cf">for</span> (<span class="dt">int</span> j = <span class="dv">0</span>; j&lt;p; j++)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true"></a>{</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true"></a>    <span class="co">/* corps de boucle en O(1) */</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p>La complexité de la première boucle est en <span class="math inline">\(O(n)\)</span> et celle de la deuxième en <span class="math inline">\(O(p)\)</span>. La complexité globale est en <span class="math inline">\(O(n+p)\)</span> car <span class="math inline">\(n \le n+p\)</span> et <span class="math inline">\(p \le n+p\)</span>.</p>
<h2 data-number="3.6" id="sec:complexité-en-moyenne"><span class="header-section-number">3.6</span> Complexité en moyenne</h2>
<p>On reprend ici les notations de la partie <a href="#sec:complexité-dans-le-pire-des-cas">Complexité dans le pire des cas</a>.</p>
<p><div class="ui message"><div class="header">Définition</div> Lorsque pour tout <span class="math inline">\(n \in \N\)</span>, <span class="math inline">\(I_n\)</span> est fini, on appelle :</p>
<ul>
<li><strong>complexité temporelle en moyenne</strong> la suite <span class="math inline">\((C^{t,m}_n) = \frac{1}{|I_n|} \sum_{e\in I_n} t(e)\)</span>.</li>
<li><strong>complexité spatiale en moyenne</strong> la suite <span class="math inline">\((C^{s,m}_n) = \frac{1}{|I_n|} \sum_{e\in I_n} s(e)\)</span>. </div></li>
</ul>
<p>On peut étendre cette définition à un cadre infini en considérant une distribution de probabilité sur <span class="math inline">\(I_n\)</span> et <span class="math inline">\(T_n\)</span> la variable aléatoire associée à <span class="math inline">\(t\)</span> sur <span class="math inline">\(I_n\)</span>. Si <span class="math inline">\(T_n\)</span> est d’espérance finie, on pourra parler de complexité en moyenne pour la suite des <span class="math inline">\(E(T_n)\)</span>. Concrètement, on considère alors une fonction <span class="math inline">\(p_n : I_n \rightarrow [0,1]\)</span> telle que <span class="math inline">\(\sum_{e \in I_n} p(e) = 1\)</span> et, lorsque la somme est définie, on note ainsi <span class="math display">\[C^{t,m}_n = \sum_{e \in I_n} p(e) t(e)\]</span> <span class="math display">\[C^{s,m}_n = \sum_{e \in I_n} p(e) s(e)\]</span></p>
<p>Un exemple usuel de calcul de complexité en moyenne est celui des tris. En effet, même si les entrées de taille <span class="math inline">\(n\)</span> sont infinies, on peut considérer qu’un tableau de valeurs deux à deux distinctes est l’image par une permutation du tableau triée. Si le tableau est de taille <span class="math inline">\(n\)</span>, on aura ainsi <span class="math inline">\(n!\)</span> permutations ce qui permet, du moment que l’algorithme de tri considéré ne dépend que cette permutation, de calculer la complexité en moyenne sur l’ensemble des permutations.</p>
<p><div class="ui message orange"><div class="header">Remarque</div>Les permutations d’un ensemble sont les applications bijectives de cet ensemble dans lui-même. Si l’ensemble contient <span class="math inline">\(n\)</span> éléments, il y a <span class="math inline">\(n!\)</span> permutations.</p>
<p>Par exemple, les six permutations sur l’ensemble <span class="math inline">\(\{1,2,3\}\)</span> correspondent aux diagrammes sagittaires suivants :</p>
<p><img src="assets/pics/permutation_s6.png" /></p>
<p>Ces six permutations correspondant elles-mêmes, de gauche à droite et de haut en bas, aux tableaux <code>{1,2,3}</code>, <code>{1,3,2}</code>, <code>{3,2,1}</code>, <code>{2,1,3}</code>, <code>{2,3,1}</code> et <code>{3,1,2}</code>. </div></p>
<h3 data-number="3.6.1" id="sec:exemple-de-calcul-de-complexité-temporelle-en-moyenne"><span class="header-section-number">3.6.1</span> Exemple de calcul de complexité temporelle en moyenne</h3>
<p>On considère la recherche linéaire vue dans la partie <a href="#sec:complexité-linéaire">Complexité linéaire</a>. L’ensemble des entrées est ici infini, on va donc supposer pour faire le calcul qu’on ne considère que des tableaux de valeurs deux à deux distinctes et qu’on recherche un élément présent dans le tableau, chaque élément étant équiprobable.</p>
<p>Si on recherche le <span class="math inline">\(i\)</span>-ème élément du tableau, l’algorithme effectue <span class="math inline">\(i\)</span> itérations avant d’y accéder et de renvoyer son indice. Ainsi, le temps pour cet entrée est de <span class="math inline">\(i C\)</span> où <span class="math inline">\(C\)</span> est le coût d’une itération.</p>
<p>La complexité temporelle en moyenne est alors <span class="math inline">\(C^{t,m}_n = \sum_{i=1}^{n} \frac{1}{n} i C = \frac{(n+1)C}{2} = O(n)\)</span>. On retrouve ici la même complexité que la complexité dans le pire des cas. La sortie prématurée de la boucle n’a donc aucune influence sur la complexité.</p>
<h2 data-number="3.7" id="sec:complexité-amortie"><span class="header-section-number">3.7</span> Complexité amortie</h2>
<p>Dans le cadre de l’étude des structures de données, il est fréquent de considérer non pas la complexité dans le pire des cas d’une opération mais celle d’une succession d’opérations divisée par le nombre d’opérations effectuées. Ainsi, on peut très bien avoir une opération ponctuellement plus coûteuse que les autres, mais en procédant ainsi on lisse le surcoût sur l’ensemble des opérations. On parle alors de <strong>complexité amortie</strong>.</p>
<p><div class="ui message orange"><div class="header">Remarque</div>Cette notion ne masque pas le fait qu’une opération puisse prendre ponctuellement plus de temps. Dans des contextes temps réel où il est importat de maitriser pleinement les complexités, il est peu judicieux d’utiliser de telles complexités. Par exemple, dans une visualisation en 3D, pour maintenir un débit constant d’images par secondes, chaque image doit prendre un temps similaire. Se reposer sur une structure de donnée ayant une faible complexité amortie mais une complexité dans le pire des cas importante, c’est risquer d’avoir des sacades avec une image qui prendrait plus de temps pour être calculée.</div></p>
<p>Un exemple simple est donnée par la structure de données des tableaux dynamiques. C’est la structure de données utilisées dans de nombreux langages de haut niveau pour implémenter le type abstrait des listes. La différence principale entre cette structure de données et celle des tableaux de C est qu’on peut ajouter et supprimer des éléments.</p>
<p>Un tableau dynamique d’entiers est un triplet <code>(t,c,n)</code> où <code>t</code> est un tableau de taille <code>c</code>, appelée la capacité du tableau dynamique, et <code>n</code> est un autre entier représentant la taille logique du tableau. A tout moment <span class="math inline">\(c \ge n\)</span>. Dans <code>t</code> il y a ainsi <span class="math inline">\(c-n\)</span> cases déjà allouées qui permettent de rajouter un élément en temps constant. Quand <span class="math inline">\(c=n\)</span>, on alloue une nouvelle zone mémoire, souvent de taille <span class="math inline">\(2c\)</span>, on déplace le tableau <code>t</code> dans cette zone et on a donc pour cet ajout prévu un certain nombre de cases d’avance.</p>
<p>La figure suivante présente une succession d’ajouts : <img src="assets/pics/tableau_dyn.png" /></p>
<p>Une implémentation de ces opérations est proposée dans le programme suivant :</p>
<p><div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true"></a><span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true"></a><span class="kw">typedef</span> <span class="kw">struct</span> {</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true"></a>    <span class="dt">int</span> *t;</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true"></a>    <span class="dt">size_t</span> c;</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true"></a>    <span class="dt">size_t</span> n;</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true"></a>} tableau_dynamique ;</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true"></a>tableau_dynamique tableau_dynamique_creer()</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true"></a>{</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true"></a>    tableau_dynamique d;</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true"></a>    <span class="dt">const</span> <span class="dt">size_t</span> capacite_initiale = <span class="dv">2</span>;</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true"></a>    d.t = malloc(capacite_initiale * <span class="kw">sizeof</span>(<span class="dt">int</span>));</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true"></a>    d.c = capacite_initiale;</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true"></a>    d.n = <span class="dv">0</span>;</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true"></a>    <span class="cf">return</span> d;</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true"></a>}</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true"></a><span class="dt">void</span> tableau_dynamique_ajout(tableau_dynamique *d, <span class="dt">int</span> x)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true"></a>{</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true"></a>    <span class="cf">if</span> (d-&gt;c == d-&gt;n) {</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true"></a>        d-&gt;c = <span class="dv">2</span> * d-&gt;c;</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true"></a>        d-&gt;t = realloc(d-&gt;t, d-&gt;c * <span class="kw">sizeof</span>(<span class="dt">int</span>));</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true"></a>    }</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true"></a>    d-&gt;t[d-&gt;n] = x;</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true"></a>    d-&gt;n++;</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true"></a>}</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true"></a><span class="dt">void</span> tableau_dynamique_print(tableau_dynamique d)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true"></a>{</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true"></a>    printf(<span class="st">&quot;c=%d</span><span class="sc">\t</span><span class="st">n=%d</span><span class="sc">\t</span><span class="st">|&quot;</span>, d.c, d.n);</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true"></a>    <span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; d.n; i++) {</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true"></a>        printf(<span class="st">&quot;%d|&quot;</span>, d.t[i]);</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true"></a>    }</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true"></a>    <span class="cf">for</span> (<span class="dt">size_t</span> i = d.n; i &lt; d.c; i++) {</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true"></a>        printf(<span class="st">&quot; |&quot;</span>);</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true"></a>    }</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true"></a>    printf(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>);</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true"></a>}</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true"></a></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true"></a><span class="dt">int</span> main(<span class="dt">void</span>) {</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true"></a>    tableau_dynamique d = tableau_dynamique_creer();</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true"></a>    tableau_dynamique_print(d); </span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true"></a>    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">1</span>; i &lt; <span class="dv">6</span>; i++) {</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true"></a>        tableau_dynamique_ajout(&amp;d,i);</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true"></a>        tableau_dynamique_print(d); </span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true"></a>    }</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true"></a>}</span></code></pre></div>
<p></div></p>
<p>Ce programme, une fois exécuté produit la sortie suivante qui permet de retrouver exactement le comportement attendu :</p>
<p><div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true"></a>c=<span class="dv">2</span> n=<span class="dv">0</span> | | |</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true"></a>c=<span class="dv">2</span> n=<span class="dv">1</span> |<span class="dv">1</span>| |</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true"></a>c=<span class="dv">2</span> n=<span class="dv">2</span> |<span class="dv">1</span>|<span class="dv">2</span>|</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true"></a>c=<span class="dv">4</span> n=<span class="dv">3</span> |<span class="dv">1</span>|<span class="dv">2</span>|<span class="dv">3</span>| |</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true"></a>c=<span class="dv">4</span> n=<span class="dv">4</span> |<span class="dv">1</span>|<span class="dv">2</span>|<span class="dv">3</span>|<span class="dv">4</span>|</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true"></a>c=<span class="dv">8</span> n=<span class="dv">5</span> |<span class="dv">1</span>|<span class="dv">2</span>|<span class="dv">3</span>|<span class="dv">4</span>|<span class="dv">5</span>| | | |</span></code></pre></div>
<p></div></p>
<p>Calculons la complexité amortie de l’ajout d’un élément. Si on considère un ajout d’élément qui provoque une réallocation du tableau, celle-ci sera en <span class="math inline">\(O(c)\)</span> et les <span class="math inline">\(c-1\)</span> opérations suivantes d’ajout seront en <span class="math inline">\(O(1)\)</span>. La complexité globale de ces <span class="math inline">\(c\)</span> opérations d’ajout est alors en <span class="math inline">\(O(c)\)</span>, ce qui donne une complexité amortie en <span class="math inline">\(O(1)\)</span>. On peut ainsi considérer que l’ajout d’un élément dans un tableau dynamique est en complexité temporelle amortie constante.</p>
<p><div class="ui message blue"><div class="header">Note</div>Il faut faire un choix entre reprendre ici une preuve plus précise ou la garder pour un chapitre ultérieur avec au moins un exemple de méthode du potentiel (Skew Heaps?)</div></p>
<h2 data-number="3.8" id="sec:pertinence-de-la-complexité-spatiale"><span class="header-section-number">3.8</span> Pertinence de la complexité spatiale</h2>
<p>Même si la complexité temporelle est le plus souvent celle qui est importante à calculer, certains algorithmes ont une complexité temporelle faible mais en contrepartie une complexité spatiale élevée. On parle alors de compromis temps-mémoire.</p>
<p>Un exemple classique d’un tel compromis est celui de la programmation dynamique où on passe d’une complexité temporelle exponentielle à une complexité temporelle polynomiale en stockant des valeurs intermédiaires pour ne pas les recalculer. En procédant ainsi, on passe d’une complexité spatiale constante à polynomiale.</p>
<p>Cela est illustré dans le programme suivant qui permet de déterminer le <span class="math inline">\(n\)</span>-ième terme de la suite de Fibonacci, ce qui n’a pas d’intérêt informatique mais est caractéristique de récurrence que l’on résoudra par la programmation dynamique.</p>
<p><div class="ui segment" style="font-size:0.8em" ></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true"></a><span class="co">(* Fibonacci exponentiel *)</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true"></a><span class="kw">let</span> <span class="kw">rec</span> fibo n =</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true"></a>    <span class="kw">if</span> n = <span class="dv">0</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true"></a>    <span class="kw">then</span> <span class="dv">0</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true"></a>    <span class="kw">else</span> <span class="kw">if</span> n = <span class="dv">1</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true"></a>    <span class="kw">then</span> <span class="dv">1</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true"></a>    <span class="kw">else</span> fibo (n<span class="dv">-1</span>) + fibo (n<span class="dv">-2</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true"></a><span class="co">(* Fibonacci linéaire *)</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true"></a><span class="kw">let</span> fibo n =</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true"></a>    <span class="kw">let</span> prec = <span class="dt">Array</span>.make (n+<span class="dv">1</span>) <span class="dv">0</span> <span class="kw">in</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true"></a>    prec.(<span class="dv">0</span>) &lt;- <span class="dv">0</span>;</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true"></a>    prec.(<span class="dv">1</span>) &lt;- <span class="dv">1</span>;</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true"></a>    <span class="kw">for</span> i = <span class="dv">2</span> <span class="kw">to</span> n <span class="kw">do</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true"></a>        prec.(i) &lt;- prec.(i<span class="dv">-1</span>) + prec.(i<span class="dv">-2</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true"></a>    <span class="kw">done</span>;</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true"></a>    prec.(n)</span></code></pre></div>
<p></div></p>
</div>
</div>
</div>

<div class="ui inverted vertical footer segment">
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Licence Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
Marc de Falco
</div>

  </body>
</html>
